{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce43ec99",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "We are a Surveillance and CCTV company. We have a standard CCTV system, and we want to upgrade it into smart CCTVs. We want a solution that enables our cameras to detect human patterns, count objects, provide analysis within a 24-hour cooldown, and correctly detect the proper alert action for the system.\n",
    "\n",
    "# Data Science Methodology\n",
    "\n",
    "Let's apply the Data Science Methodology. \n",
    "\n",
    "Important note: it is really hard to mimic real-case projects. Below points describe assumptions and differences between any personal project/research and real-case scenario project.\n",
    "\n",
    "- **Raw Data**: In my personal project, I am going to collect video and image data from more than one resource. However, if I want to be more accurate, I cannot call it raw data. This is because most resources are providing data already labeled (annotated). **Annotation** consume heavy resources from the team. In addition to annotation, ETL process will be missing in my personal project where in real cases data are being stored in certain Data Base where collection requires queries (assuming that there is no platform specifically to the firm purposes). For example, I have worked in a company where the collection of data is through platform, where me as a data scientist did not need any ETL techniques, queries, or communicating with a Data Engineer to help in ETL process. Meaning that, the job of Data Engineering and ETL might be done one time, enabling analysts and scientist to perform ETL process easily and lonely in the future. \n",
    "\n",
    "## Surveillance and Alarm Management Business Understanding and Problem Definition\n",
    "\n",
    "I can conclude that they have CCTVs that are designed for **standard monitoring activities**, where cameras are capturing normal videos. Meaning that video and image data that we should use to train the model contains standard CCTV captures, not advanced videos and images like thermal captures nor medical and microbial captures.\n",
    "\n",
    "However, it was mentioned in the problem statement that they don't need to detect anomalies only! Stakeholders want also to have smart cameras that provide analysis on daily basis like counting and identifying categories, meaning that we are looking to achieve the following goals:\n",
    "\n",
    "- To enable cameras accurately detect positive alarms and minimize false and missing alarms. I will discuss more about this point in the model evaluation stage.\n",
    "\n",
    "- To enable the model to integrate with the CCTV system by upgrading it to intelligent level. Below list shows new features to be added:\n",
    "    - Provide daily basis counting to objects. This requires to train the model with various categories, so it can correctly identify objects in real time. I will add *New* as feature so whenever a new class that the model does not know, the data scientist then label captures manually and train and new model based on that. This is an iterative process, and it is a part of optimizing the models almost in daily basis.\n",
    "    - We need to include in the daily analysis dashboards a section for counting patterns. i.e., in addition labeling anomalies, I will introduce normal patterns, for example but not limited to: paying in supermarket, walking, driving/parking, gender prediction, and many many ideas that could lead to insights. In real case, this should be discussed with stakeholders twice per week or minimum once. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Data Collection Criteria and Strategy\n",
    "\n",
    "During my graduate degree I used to implement Computer Vision projects for the purpose of learning Deep Learning algorithms as theory. However, in this project I will use raw data that is not being annotated.\n",
    "\n",
    "### VIRAT Video Dataset Overview\n",
    "\n",
    "The VIRAT dataset is a popular benchmark for human and vehicle activity detection in surveillance videos. It includes realistic scenes recorded from various camera angles across different locations in the U.S., with over 40 labeled activities.\n",
    "\n",
    "Video quality varies—some clips are high-resolution, others low—with people appearing at different sizes and frame rates ranging from 2 to 30 FPS. It's designed to reflect real-world conditions, which makes it great for testing models on practical surveillance data.\n",
    "\n",
    "Access requires approval via the official VIRAT website. Once granted, the full dataset (videos + annotations) can be downloaded through provided links.\n",
    "\n",
    "#### Reason for Exclusion\n",
    "\n",
    "Although the dataset is high quality, I won’t be using it because of its size—over **550 GB**. It’s too large to handle efficiently within my current resources.\n",
    "\n",
    "#### Alternative: TinyVIRAT Dataset\n",
    "\n",
    "As a smaller option, I explored **TinyVIRAT**, a scaled-down dataset (~3.6 GB) made for quick experiments. It includes short, low-resolution video clips with multiple action labels, ideal for lightweight testing.\n",
    "\n",
    "The GitHub repo ([Tiny-VIRAT](https://github.com/UgurDemir/Tiny-VIRAT)) provides helper scripts and documentation. To get the actual videos, you can directly download them from:\n",
    "\n",
    "- [https://www.crcv.ucf.edu/tiny-actions-challenge-cvpr2021/data/TinyVIRAT-v2.zip](https://www.crcv.ucf.edu/tiny-actions-challenge-cvpr2021/data/TinyVIRAT-v2.zip)\n",
    "\n",
    "TinyVIRAT is helpful for prototyping but doesn't fully replace the coverage or complexity of the full VIRAT dataset.\n",
    "\n",
    "#### References\n",
    "\n",
    "- VIRAT Dataset Official Website: [https://www.viratdata.org/](https://www.viratdata.org/)\n",
    "- Tiny-VIRAT GitHub: [https://github.com/UgurDemir/Tiny-VIRAT](https://github.com/UgurDemir/Tiny-VIRAT)\n",
    "- Tiny-VIRAT-v2 Download: [https://www.crcv.ucf.edu/tiny-actions-challenge-cvpr2021/data/TinyVIRAT-v2.zip](https://www.crcv.ucf.edu/tiny-actions-challenge-cvpr2021/data/TinyVIRAT-v2.zip)\n",
    "- Roboflow Hosted Subset: [https://universe.roboflow.com/radoslaw-kawczak/virat-v2](https://universe.roboflow.com/radoslaw-kawczak/virat-v2)\n",
    "\n",
    "### Data Management\n",
    "\n",
    "To manage datasets more effectively, I will store and organize my data using Hugging Face. I plan to create dataset repositories and use Python libraries provided by Hugging Face for upload, and effective version control.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model Evaluation - Definitions in the Context of Surveillance and Alarm Management\n",
    "\n",
    "\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "TP: correct positives, reflects the number of positive cases that been predicted correctly.\n",
    "\n",
    "In our project, that represents: Number of correctly predicted cases of a real threaten. \n",
    "\n",
    "TN: correct negatives, reflects the number of negative cases that been predicted correctly.\n",
    "\n",
    "In our project, that represents: Number of correctly predicted cases of normal activity (no threaten detected).\n",
    "\n",
    "FP: Wrong positives, reflects the number of negative cases that been predicted wrongly as positive\n",
    "\n",
    "In our project, that represents: Number of wrongly predicted cases of normal activities as a real threaten. Which is in alarm management called `False Alarm`\n",
    "\n",
    "FN : Missed positives, reflects the number of positive cases that been predicted wrongly as negative\n",
    "\n",
    "In our project, that represents: Number of wrongly predicted cases of real threaten as a normal activity. In the context of alarm management this represents a real threaten that being not predicted. This metric considered the most dangerous one and we want our model to have the most minimum value as possible, where zero cases is the optimum result we must aim to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd91df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries\n",
    "\n",
    "import glob # read mp4 file\n",
    "import os\n",
    "import cv2 # used poetry add opencv-python\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0673678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .mp4 files found: 12829\n"
     ]
    }
   ],
   "source": [
    "# Set the root folder path\n",
    "root_folder = r\"D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\"  # Replace with your actual path\n",
    "\n",
    "# Find all .mp4 files recursively\n",
    "mp4_files = glob.glob(os.path.join(root_folder, \"**\", \"*.mp4\"), recursive=True)\n",
    "\n",
    "# Print number of mp4 files\n",
    "print(f\"Total .mp4 files found: {len(mp4_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2c190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5570.mp4\n",
      "D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5571.mp4\n",
      "D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5572.mp4\n",
      "D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5573.mp4\n",
      "D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5574.mp4\n"
     ]
    }
   ],
   "source": [
    "for file in mp4_files[:5]:  # Preview first 5 files\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0363d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video: D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5570.mp4\n",
      "Resolution: 112x112\n",
      "FPS: 29.97\n",
      "Total Frames: 100\n",
      "Duration (s): 3.34\n",
      "\n",
      "Video: D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5571.mp4\n",
      "Resolution: 128x128\n",
      "FPS: 29.97\n",
      "Total Frames: 113\n",
      "Duration (s): 3.77\n",
      "\n",
      "Video: D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5572.mp4\n",
      "Resolution: 34x34\n",
      "FPS: 29.97\n",
      "Total Frames: 101\n",
      "Duration (s): 3.37\n",
      "\n",
      "Video: D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5573.mp4\n",
      "Resolution: 30x30\n",
      "FPS: 29.97\n",
      "Total Frames: 121\n",
      "Duration (s): 4.04\n",
      "\n",
      "Video: D:\\2-Datasets from Various Resources\\Tiny-VARIAT\\Tiny_VIRAT_v1\\VIRAT_S_000000\\5574.mp4\n",
      "Resolution: 28x28\n",
      "FPS: 29.97\n",
      "Total Frames: 91\n",
      "Duration (s): 3.04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preview a few sample videos\n",
    "for video_path in mp4_files[:5]:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = frame_count / fps if fps else 0\n",
    "\n",
    "    print(f\"\\nVideo: {video_path}\")\n",
    "    print(f\"Resolution: {width}x{height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Total Frames: {frame_count}\")\n",
    "    print(f\"Duration (s): {duration:.2f}\")\n",
    "\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5330d227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>resolution</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\2-Datasets from Various Resources\\Tiny-VARI...</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112x112</td>\n",
       "      <td>29.97</td>\n",
       "      <td>100</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\2-Datasets from Various Resources\\Tiny-VARI...</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128x128</td>\n",
       "      <td>29.97</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\2-Datasets from Various Resources\\Tiny-VARI...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34x34</td>\n",
       "      <td>29.97</td>\n",
       "      <td>101</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\2-Datasets from Various Resources\\Tiny-VARI...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30x30</td>\n",
       "      <td>29.97</td>\n",
       "      <td>121</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\2-Datasets from Various Resources\\Tiny-VARI...</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28x28</td>\n",
       "      <td>29.97</td>\n",
       "      <td>91</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  width  height  \\\n",
       "0  D:\\2-Datasets from Various Resources\\Tiny-VARI...    112     112   \n",
       "1  D:\\2-Datasets from Various Resources\\Tiny-VARI...    128     128   \n",
       "2  D:\\2-Datasets from Various Resources\\Tiny-VARI...     34      34   \n",
       "3  D:\\2-Datasets from Various Resources\\Tiny-VARI...     30      30   \n",
       "4  D:\\2-Datasets from Various Resources\\Tiny-VARI...     28      28   \n",
       "\n",
       "  resolution    fps  frame_count  duration_sec  \n",
       "0    112x112  29.97          100          3.34  \n",
       "1    128x128  29.97          113          3.77  \n",
       "2      34x34  29.97          101          3.37  \n",
       "3      30x30  29.97          121          4.04  \n",
       "4      28x28  29.97           91          3.04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting the metadata into pandas DataFrame\n",
    "video_metadata = []\n",
    "\n",
    "for path in mp4_files:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        continue\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = frame_count / fps if fps else 0\n",
    "\n",
    "    video_metadata.append({\n",
    "        \"file_path\": path,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"resolution\": f\"{width}x{height}\",\n",
    "        \"fps\": round(fps, 2),\n",
    "        \"frame_count\": frame_count,\n",
    "        \"duration_sec\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Create DataFrame\n",
    "df_metadata = pd.DataFrame(video_metadata)\n",
    "\n",
    "# Preview the first few rows\n",
    "df_metadata.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
